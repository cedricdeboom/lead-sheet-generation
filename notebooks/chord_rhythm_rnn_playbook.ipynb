{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f91184884b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(3333)\n",
    "torch.manual_seed(3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch RNN axes:\n",
    "# 1. The first axis is the sequence itself,\n",
    "# 2. the second indexes instances in the mini-batch,\n",
    "# 3. and the third indexes elements of the input.\n",
    "\n",
    "# But we will put the batch axis in front (through the batch_first=True argument)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.batch_size, self.num_layers, self.hidden_dim),\n",
    "                torch.zeros(self.batch_size, self.num_layers, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input_X, lengths_X, max_length, temperature=1.0):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [batch_size, input_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both have shape (batch_size, num_layers, hidden_dim).\n",
    "        packed_X = torch.nn.utils.rnn.pack_padded_sequence(input_X, lengths_X, batch_first=True)\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(packed_X)\n",
    "        \n",
    "        unpacked_X, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True, total_length=max_length)\n",
    "        \n",
    "        # Generate sequence predictions\n",
    "        X_pred = self.linear(unpacked_X)\n",
    "        \n",
    "        # Apply nonlinearities\n",
    "        X_softmax_1 = F.log_softmax(X_pred[:, :, :13] / temperature, dim=2)\n",
    "        X_softmax_2 = F.log_softmax(X_pred[:, :, 13:] / temperature, dim=2)\n",
    "        \n",
    "        # Concatenate the two tensors along axis 2\n",
    "        X_return = torch.cat((X_softmax_1, X_softmax_2), 2)\n",
    "        \n",
    "        return X_return\n",
    "\n",
    "model = LSTM(input_dim=62, hidden_dim=512, batch_size=1, output_dim=62, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATALOADER FOR MUSIC FILES\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, data_path, sequence_length=100):\n",
    "        super(MusicDataset, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        with open('processed_numpy/data.pkl', 'rb') as f:\n",
    "            self.id_to_sheet = pickle.load(f)\n",
    "            self.data = pickle.load(f)\n",
    "        \n",
    "        self.data = [x.astype(np.float32) for x in self.data]\n",
    "        \n",
    "        # pad all sequences to desired sequence length\n",
    "        self.mask_lengths = []\n",
    "        for i, x in enumerate(self.data):\n",
    "            if len(x) < self.sequence_length + 1:\n",
    "                s = x.shape\n",
    "                self.data[i] = np.zeros((self.sequence_length + 1, s[1]), dtype=np.float32)\n",
    "                self.data[i][:s[0], :] = x\n",
    "                self.mask_lengths.append(s[0] - 1)\n",
    "            else:\n",
    "                self.mask_lengths.append(self.sequence_length)\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return sys.maxsize\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        data_index = np.random.randint(0, len(self.data))\n",
    "        data_point = self.data[data_index][:, 130:]\n",
    "        \n",
    "        data_range = np.random.randint(0, len(data_point) - self.sequence_length)\n",
    "        \n",
    "        # return original sequence, target sequence, and original sequence lengths\n",
    "        return (\n",
    "            data_point[data_range:(data_range + self.sequence_length)],\n",
    "            data_point[data_range + 1:(data_range + self.sequence_length + 1)],\n",
    "            np.asarray(self.mask_lengths[data_index], dtype=np.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MusicDataset('processed_numpy/data.pkl', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_loader = DataLoader(md, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(data_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0] = X[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][0][:, 13:-1] = np.roll(X[0][0][:, 13:-1], 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences should be sorted decreasing in length\n",
    "def sort_batch(batch_data):\n",
    "    batch_data[0] = batch_data[0][[x for _,x in sorted(zip(batch_data[2], range(0, 200)), reverse=True)]]\n",
    "    batch_data[1] = batch_data[1][[x for _,x in sorted(zip(batch_data[2], range(0, 200)), reverse=True)]]\n",
    "    batch_data[2] = batch_data[2][[x for _,x in sorted(zip(batch_data[2], range(0, 200)), reverse=True)]]\n",
    "    \n",
    "sort_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch_data):\n",
    "    return [x.cuda() for x in batch_data]\n",
    "    \n",
    "X = to_cuda(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = model(X[0], X[2], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1][31][49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 62])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "        100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "        100., 100., 100., 100., 100., 100.,  60.,  59.], device='cuda:0')"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(output, target, lenghts):\n",
    "    logit_targets = output * target\n",
    "    ce_1 = torch.mean(torch.sum(-torch.sum(logit_targets[:, :, :13], dim=2), dim=1) / lenghts)\n",
    "    ce_2 = torch.mean(torch.sum(-torch.sum(logit_targets[:, :, 13:], dim=2), dim=1) / lenghts)\n",
    "    return ce_1 + ce_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6997, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss(Y, X[1], X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  6.45391321182251\n",
      "Epoch  50 MSE:  4.432456016540527\n",
      "Epoch  100 MSE:  4.166339874267578\n",
      "Epoch  150 MSE:  3.4746432304382324\n",
      "Epoch  200 MSE:  2.928406000137329\n",
      "Epoch  250 MSE:  2.2210330963134766\n",
      "Epoch  300 MSE:  2.060547351837158\n",
      "Epoch  350 MSE:  1.8461823463439941\n",
      "Epoch  400 MSE:  1.8069108724594116\n",
      "Epoch  450 MSE:  1.568809151649475\n",
      "Epoch  500 MSE:  1.7201910018920898\n",
      "Epoch  550 MSE:  1.6085624694824219\n",
      "Epoch  600 MSE:  1.5100370645523071\n",
      "Epoch  650 MSE:  1.7032045125961304\n",
      "Epoch  700 MSE:  1.515383243560791\n",
      "Epoch  750 MSE:  1.5181396007537842\n",
      "Epoch  800 MSE:  1.407153844833374\n",
      "Epoch  850 MSE:  1.5526185035705566\n",
      "Epoch  900 MSE:  1.481121301651001\n",
      "Epoch  950 MSE:  1.4455305337905884\n",
      "Epoch  1000 MSE:  1.3509211540222168\n",
      "Epoch  1050 MSE:  1.576219081878662\n",
      "Epoch  1100 MSE:  1.567812442779541\n",
      "Epoch  1150 MSE:  1.4649074077606201\n",
      "Epoch  1200 MSE:  1.4041048288345337\n",
      "Epoch  1250 MSE:  1.3846971988677979\n",
      "Epoch  1300 MSE:  1.4110180139541626\n",
      "Epoch  1350 MSE:  1.4043363332748413\n",
      "Epoch  1400 MSE:  1.3021522760391235\n",
      "Epoch  1450 MSE:  1.4172661304473877\n",
      "Epoch  1500 MSE:  1.3740260601043701\n",
      "Epoch  1550 MSE:  1.4603842496871948\n",
      "Epoch  1600 MSE:  1.29768705368042\n",
      "Epoch  1650 MSE:  1.495441198348999\n",
      "Epoch  1700 MSE:  1.3485383987426758\n",
      "Epoch  1750 MSE:  1.4272525310516357\n",
      "Epoch  1800 MSE:  1.2966225147247314\n",
      "Epoch  1850 MSE:  1.4066835641860962\n",
      "Epoch  1900 MSE:  1.2788445949554443\n",
      "Epoch  1950 MSE:  1.3394875526428223\n",
      "Epoch  2000 MSE:  1.3282537460327148\n",
      "Epoch  2050 MSE:  1.3395607471466064\n",
      "Epoch  2100 MSE:  1.2875854969024658\n",
      "Epoch  2150 MSE:  1.315873622894287\n",
      "Epoch  2200 MSE:  1.3996003866195679\n",
      "Epoch  2250 MSE:  1.2075062990188599\n",
      "Epoch  2300 MSE:  1.1622231006622314\n",
      "Epoch  2350 MSE:  1.1946430206298828\n",
      "Epoch  2400 MSE:  1.339733362197876\n",
      "Epoch  2450 MSE:  1.2863411903381348\n",
      "Epoch  2500 MSE:  1.2286183834075928\n",
      "Epoch  2550 MSE:  1.2158820629119873\n",
      "Epoch  2600 MSE:  1.289780616760254\n",
      "Epoch  2650 MSE:  1.1936359405517578\n",
      "Epoch  2700 MSE:  1.2193171977996826\n",
      "Epoch  2750 MSE:  1.133231520652771\n",
      "Epoch  2800 MSE:  1.1687341928482056\n",
      "Epoch  2850 MSE:  1.1964977979660034\n",
      "Epoch  2900 MSE:  1.2830383777618408\n",
      "Epoch  2950 MSE:  1.0990118980407715\n",
      "Epoch  3000 MSE:  1.223433256149292\n",
      "Epoch  3050 MSE:  1.2418397665023804\n",
      "Epoch  3100 MSE:  1.4083601236343384\n",
      "Epoch  3150 MSE:  1.2659270763397217\n",
      "Epoch  3200 MSE:  1.2127363681793213\n",
      "Epoch  3250 MSE:  1.2807261943817139\n",
      "Epoch  3300 MSE:  1.1466096639633179\n",
      "Epoch  3350 MSE:  1.149728775024414\n",
      "Epoch  3400 MSE:  1.1551586389541626\n",
      "Epoch  3450 MSE:  1.2215036153793335\n",
      "Epoch  3500 MSE:  1.149619221687317\n",
      "Epoch  3550 MSE:  1.1650185585021973\n",
      "Epoch  3600 MSE:  1.192276954650879\n",
      "Epoch  3650 MSE:  1.034846544265747\n",
      "Epoch  3700 MSE:  1.1037176847457886\n",
      "Epoch  3750 MSE:  1.1190754175186157\n",
      "Epoch  3800 MSE:  1.1619236469268799\n",
      "Epoch  3850 MSE:  1.0855371952056885\n",
      "Epoch  3900 MSE:  1.1091740131378174\n",
      "Epoch  3950 MSE:  1.1522724628448486\n",
      "Epoch  4000 MSE:  1.2461411952972412\n",
      "Epoch  4050 MSE:  1.1466768980026245\n",
      "Epoch  4100 MSE:  1.1622027158737183\n",
      "Epoch  4150 MSE:  1.0111387968063354\n",
      "Epoch  4200 MSE:  1.1208651065826416\n",
      "Epoch  4250 MSE:  1.044081211090088\n",
      "Epoch  4300 MSE:  1.1249643564224243\n",
      "Epoch  4350 MSE:  0.9982128739356995\n",
      "Epoch  4400 MSE:  1.078223466873169\n",
      "Epoch  4450 MSE:  1.0567089319229126\n",
      "Epoch  4500 MSE:  0.9947878122329712\n",
      "Epoch  4550 MSE:  1.0325138568878174\n",
      "Epoch  4600 MSE:  1.0226068496704102\n",
      "Epoch  4650 MSE:  0.9520744681358337\n",
      "Epoch  4700 MSE:  1.002083420753479\n",
      "Epoch  4750 MSE:  1.0021889209747314\n",
      "Epoch  4800 MSE:  1.0381593704223633\n",
      "Epoch  4850 MSE:  1.1124615669250488\n",
      "Epoch  4900 MSE:  0.9458411931991577\n",
      "Epoch  4950 MSE:  0.8850358724594116\n",
      "Epoch  5000 MSE:  0.9078084230422974\n",
      "Epoch  5050 MSE:  0.99509596824646\n",
      "Epoch  5100 MSE:  0.8048778772354126\n",
      "Epoch  5150 MSE:  0.9680771827697754\n",
      "Epoch  5200 MSE:  1.0057895183563232\n",
      "Epoch  5250 MSE:  0.8647572994232178\n",
      "Epoch  5300 MSE:  0.9325765371322632\n",
      "Epoch  5350 MSE:  0.993264377117157\n",
      "Epoch  5400 MSE:  0.8276773691177368\n",
      "Epoch  5450 MSE:  0.8730568289756775\n",
      "Epoch  5500 MSE:  0.9243066310882568\n",
      "Epoch  5550 MSE:  0.9052098989486694\n",
      "Epoch  5600 MSE:  0.9423874020576477\n",
      "Epoch  5650 MSE:  1.009061574935913\n",
      "Epoch  5700 MSE:  0.9301691055297852\n",
      "Epoch  5750 MSE:  0.8415055274963379\n",
      "Epoch  5800 MSE:  0.8520897626876831\n",
      "Epoch  5850 MSE:  0.8151073455810547\n",
      "Epoch  5900 MSE:  0.8546838164329529\n",
      "Epoch  5950 MSE:  0.7866601347923279\n",
      "Epoch  6000 MSE:  0.859048068523407\n",
      "Epoch  6050 MSE:  0.7484980821609497\n",
      "Epoch  6100 MSE:  0.6714818477630615\n",
      "Epoch  6150 MSE:  0.8932948708534241\n",
      "Epoch  6200 MSE:  0.8322746157646179\n",
      "Epoch  6250 MSE:  0.7556924819946289\n",
      "Epoch  6300 MSE:  0.7664229869842529\n",
      "Epoch  6350 MSE:  0.773787796497345\n",
      "Epoch  6400 MSE:  0.7837870121002197\n",
      "Epoch  6450 MSE:  0.7124518156051636\n",
      "Epoch  6500 MSE:  0.7586736679077148\n",
      "Epoch  6550 MSE:  0.7432366609573364\n",
      "Epoch  6600 MSE:  0.6496516466140747\n",
      "Epoch  6650 MSE:  0.6716684699058533\n",
      "Epoch  6700 MSE:  0.7873855829238892\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-286-2fca05955629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msort_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mY_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-274-c8da38f18293>\u001b[0m in \u001b[0;36msort_batch\u001b[0;34m(batch_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msort_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## TRAIN PROCEDURE\n",
    "learning_rate = 0.001\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for batch_idx, batch_data in enumerate(data_train_loader):\n",
    "    # zero grad model\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    # re-init hidden states\n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    sort_batch(batch_data)\n",
    "    batch_data = to_cuda(batch_data)\n",
    "    Y_output = model(batch_data[0], batch_data[2], 100)\n",
    "    Y_target = batch_data[1]\n",
    "    Y_lenghts = batch_data[2]\n",
    "    \n",
    "    loss = ce_loss(Y_output, Y_target, Y_lenghts)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    if batch_idx % 50 == 0:\n",
    "        print(\"Epoch \", batch_idx, \"MSE: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_batch(X)\n",
    "#X = to_cuda(X)\n",
    "Y = model(X[0], X[2], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fde1da3ec18>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde1dabeb00>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.exp(Y[0][10][:13].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_logits(input_sequence, length_sequence, max_length, temperature=1.0):\n",
    "    return np.random.sample(model.forward(input_sequence, length_sequence, max_length, temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-344-355d9909f8dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_from_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-343-bee941fe4cb0>\u001b[0m in \u001b[0;36msample_from_logits\u001b[0;34m(input_sequence, length_sequence, max_length, temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_from_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object does not support indexing"
     ]
    }
   ],
   "source": [
    "sample_from_logits(X[0], X[2], 100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('chord_rhythm_lstm/test/epoch_220000.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_sheets_numpy/data.pkl', 'rb') as f:\n",
    "    id_to_sheet = pickle.load(f)\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Kohlman - CRY.json\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "for i, d in enumerate(data):\n",
    "    x = d[:, 130:143]\n",
    "    for k in range(len(x)):\n",
    "        if np.argmax(x[k]) == 6:\n",
    "            print(i)\n",
    "            print(id_to_sheet[i])\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
